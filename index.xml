<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on ICASSP 2026: Human-like Spoken Dialogue Systems Challenge</title>
    <link>https://aslp-lab.github.io/HumDial-Challenge/</link>
    <description>Recent content in Home on ICASSP 2026: Human-like Spoken Dialogue Systems Challenge</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://aslp-lab.github.io/HumDial-Challenge/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>General description</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/general_description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/general_description/</guid>
      <description>Challenge Call Have you been following the recent buzz around the impressive performance of next-generation voice dialogue models like GPT-4o, Doubao, and the newly released GPT-Realtime? They are not only lightning-fast and expressive but also enable seamless multimodal interactions, making conversations feel remarkably human.
From the traditional “clunky AI” to today’s “AI assistant,” the evolution of voice dialogue systems has been nothing short of astonishing. But just how far are we from achieving truly “natural human-machine dialogue”?</description>
    </item>
    
    <item>
      <title>Get started</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/leaderboard/</guid>
      <description>Registration Teams can register by the google form: https://docs.google.com/forms/d/e/1FAIpQLSdRrlfqrhh8QhOxtKMr03AxnnX14md_EwFuIuMt-Hf4fhhARA/viewform?usp=header</description>
    </item>
    
    <item>
      <title>Timeline</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/timeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/timeline/</guid>
      <description>Timeline August 20, 2025: Registration opens September 29, 2025: Release of training set, validation set, and baseline system November 10, 2025: Release of test set November 25, 2025: Submission deadline December 7, 2025: Deadline for submitting 2-page papers to ICASSP 2026 (invited teams only) January 11, 2026: Notification of acceptance for 2-page ICASSP 2026 papers January 18, 2026: Submission of final version of papers May 4–8, 2026: ICASSP 2026 Conference, Barcelona, Spain Guidelines for participants Model Requirements: Participants may submit systems based on either end-to-end architectures or cascaded pipelines .</description>
    </item>
    
    <item>
      <title>Dataset</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/dataset/</guid>
      <description>Track 1: Emotional Intelligence
We will release a dataset consisting of hundreds of hours of human-recorded audio, including both single-turn emotional speech clips and multi-turn emotional dialogue sessions. Beyond covering a rich variety of emotional categories, the dataset features fine-grained annotations for two critical dimensions: the dynamic shifts of emotions throughout the dialogue, and the key underlying causes that trigger these emotional changes.
Track 2: Full-Duplex Interaction
We will provide multi-turn Chinese and English dialogue data from real recordings, covering typical scenarios such as speech interruptions and recognition rejection.</description>
    </item>
    
    <item>
      <title>leaderboard</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task1/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task1/leaderboard/</guid>
      <description> All results Group nameSubmission number subjects mean subjects std total score </description>
    </item>
    
    <item>
      <title>leaderboard</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task2/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task2/leaderboard/</guid>
      <description> All results Group nameSubmission number subjects mean subjects std Band 0 mean Band 1 mean Band 2 mean Band 3 mean Band 4 mean Band 5 mean Band 6 mean Band 7 mean Band 8 mean Band 9 mean total score </description>
    </item>
    
    <item>
      <title>Organizers</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/organizers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/organizers/</guid>
      <description>Organizers The challenge is organized by a distinguished team of researchers:
Lei Xie, Professor, Northwestern Polytechnical University Shuai Wang, Associate Professor, Nanjing University Haizhou Li, Professor, Chinese University of Hong Kong Eng Siong Chng, Professor, Nanyang Technological University Hung-yi Lee, Professor, Natioanl Taiwan University Chao Zhang, Assistant Professor, Tsinghua University Guangzhi Sun, Junior Research Fellow, University of Cambridge Xixin Wu, Assistant Professor, Chinese University of Hong Kong Longshuai Xiao, Huawei Technologies Zihan Zhang, Huawei Technologies Xinsheng Wang, Soul AI Lab Hui Bu, AISHELL Xin Xu， AISHELL Zhixian Zhao, Northwestern Polytechnical University Hongfei Xue, Northwestern Polytechnical University Xuelong Geng, Northwestern Polytechnical University GuoJian Li, Northwestern Polytechnical University Shuiyuan Wang, Northwestern Polytechnical University Contact For any inquiries, please contact:</description>
    </item>
    
    <item>
      <title>Task 1: Emotion Intelligence</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task1/description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task1/description/</guid>
      <description>Emotion Recognition: Identifying emotions such as happy, sad, anger, fear, neutral, surprise, and disgust from speech serves as the foundation of emotional intelligence in spoken interactions. Textual Empathy Response: Evaluating the empathy of the system’s response text, ensuring the written content reflects accurate understanding of the user’s emotional state and provides appropriate supportive expression that aligns with the user’s feelings. Auditory Empathetic Expression: Assessing the empathetic emotion conveyed by the system’s response audio, requiring the speech to carry emotional tones that match the user’s mood to achieve emotional resonance.</description>
    </item>
    
    <item>
      <title>Task 2: Full-Duplex Interaction</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task2/description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task2/description/</guid>
      <description>1. Interruption Scenarios: Negation or Dissatisfaction: The user expresses dissatisfaction during the system’s response. Follow-up Questions: The user asks further questions based on the system’s existing reply. Repetition Requests: The user asks the system to repeat previous answers. Topic Switching: The user requests a new topic during the system’s response. Silence/Termination: The user asks the system to stop speaking or end the dialogue immediately. 2. Rejection Scenarios: Pause Handling: The system should wait for the user to complete their utterance despite pauses due to thinking, hesitation, or stammering.</description>
    </item>
    
    <item>
      <title>Test Set Task 1</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task1/test_set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task1/test_set/</guid>
      <description>todo</description>
    </item>
    
    <item>
      <title>Test Set Task 2</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task2/test_set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task2/test_set/</guid>
      <description>todo</description>
    </item>
    
    <item>
      <title></title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/registration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/registration/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
