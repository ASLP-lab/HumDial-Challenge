<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on ICASSP 2026: Human-like Spoken Dialogue Systems Challenge</title>
    <link>https://aslp-lab.github.io/HumDial-Challenge/</link>
    <description>Recent content in Home on ICASSP 2026: Human-like Spoken Dialogue Systems Challenge</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://aslp-lab.github.io/HumDial-Challenge/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>General description</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/general_description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/general_description/</guid>
      <description>Challenge Call Have you also been seeing endless buzz lately about the amazing performance of next-generation voice dialogue models like GPT-4o, Doubao, and the newly released GPT-Realtime? Not only are they lightning-fast in response and expressive in voice, but they also enable smooth multimodal interactions—making it feel as if we’re truly conversing with a &amp;ldquo;real person.&amp;rdquo; From the traditional &amp;ldquo;clunky AI&amp;rdquo; to today’s &amp;ldquo;AI assistant,&amp;rdquo; the evolution of voice dialogue systems has been nothing short of astonishing.</description>
    </item>
    
    <item>
      <title>Get started</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/leaderboard/</guid>
      <description>Registration Teams can register by the google form: https://docs.google.com/forms/d/e/1FAIpQLSdRrlfqrhh8QhOxtKMr03AxnnX14md_EwFuIuMt-Hf4fhhARA/viewform?usp=header</description>
    </item>
    
    <item>
      <title>Timeline</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/timeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/timeline/</guid>
      <description>Timeline August 20, 2025: Registration opens September 20, 2025: Release of training set, validation set, and baseline system November 10, 2025: Release of test set November 25, 2025: Submission deadline December 7, 2025: Deadline for submitting 2-page papers to ICASSP 2026 (invited teams only) January 11, 2026: Notification of acceptance for 2-page ICASSP 2026 papers January 18, 2026: Submission of final version of papers May 4–8, 2026: ICASSP 2026 Conference, Barcelona, Spain Guidelines for participants Model Requirements: Participants may submit systems based on either end-to-end architectures or cascaded pipelines .</description>
    </item>
    
    <item>
      <title>Dataset</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/dataset/</guid>
      <description>The dataset is designed to cover the core scenarios of emotional intelligence and full-duplex interaction, ensuring diversity and authenticity to comprehensively evaluate the performance of participating models. It includes dialogue scenes in both Chinese and English, covering a wide range of emotional and conversational contexts. For each task in the challenge, we will provide a dedicated set of real-world recorded speech data to serve as the development (Dev) set and test (Test) set.</description>
    </item>
    
    <item>
      <title>leaderboard</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task1/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task1/leaderboard/</guid>
      <description> All results Group nameSubmission number subjects mean subjects std total score </description>
    </item>
    
    <item>
      <title>leaderboard</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task2/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task2/leaderboard/</guid>
      <description> All results Group nameSubmission number subjects mean subjects std Band 0 mean Band 1 mean Band 2 mean Band 3 mean Band 4 mean Band 5 mean Band 6 mean Band 7 mean Band 8 mean Band 9 mean total score </description>
    </item>
    
    <item>
      <title>Organizers</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/organizers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/homepage_sections/organizers/</guid>
      <description>Organizers The challenge is organized by a distinguished team of researchers:
Lei Xie, Professor, Northwestern Polytechnical University Shuai Wang, Associate Professor, Nanjing University Haizhou Li, Professor, Chinese University of Hong Kong Eng Siong Chng, Professor, Nanyang Technological University Hung-yi Lee, Professor, Natioanl Taiwan University Chao Zhang, Assistant Professor, Tsinghua University Guangzhi Sun, Junior Research Fellow, University of Cambridge Xixin Wu, Assistant Professor, Chinese University of Hong Kong Longshuai Xiao, Huawei Technologies Zihan Zhang, Huawei Technologies Xinsheng Wang, Soul AI Lab Hui Bu, AISHELL Xin Xu， AISHELL Zhixian Zhao, Northwestern Polytechnical University Hongfei Xue, Northwestern Polytechnical University Xuelong Geng, Northwestern Polytechnical University GuoJian Li, Northwestern Polytechnical University Shuiyuan Wang, Northwestern Polytechnical University Contact For any inquiries, please contact: Email: hfxue@mail.</description>
    </item>
    
    <item>
      <title>Task 1: Emotion Intelligence</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task1/description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task1/description/</guid>
      <description>Emotion Recognition: Identifying emotions such as happy, sad, anger, fear, neutral, surprise, and disgust from speech serves as the foundation of emotional intelligence in spoken interactions. Emotion Expression: Generating speech that conveys specific emotions, testing the model’s control over tone, pitch, and rhythm. Empathy Response: Responding to the user’s emotional state with appropriate emotional tone and empathy, ensuring the response reflects understanding and support for the user’s feelings. Emotion Causal Reasoning: Inferring the underlying causes of emotions in conversation, helping the model understand the user’s emotional context.</description>
    </item>
    
    <item>
      <title>Task 2: Full-Duplex Interaction</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task2/description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task2/description/</guid>
      <description>Pause Handling: The model’s ability to detect natural pauses in user speech (e.g., due to thinking or hesitation) and decide whether to take over the turn. Evaluation includes the model’s turn-over rate (TOR) and timing precision. Backchanneling (Real-Time Feedback): The model’s ability to insert appropriate short feedback expressions (like “uh-huh”, “I see”, “got it”) during user speech without disrupting the flow. Assessment will consider frequency, emotional relevance, and semantic non-interference, along with human or LLM-based scoring of naturalness and appropriateness.</description>
    </item>
    
    <item>
      <title>Test Set Task 1</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task1/test_set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task1/test_set/</guid>
      <description>todo</description>
    </item>
    
    <item>
      <title>Test Set Task 2</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/task2/test_set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/task2/test_set/</guid>
      <description>todo</description>
    </item>
    
    <item>
      <title></title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/registration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/registration/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
