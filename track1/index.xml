<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Track1s on ICASSP 2026: Human-like Spoken Dialogue Systems Challenge</title>
    <link>https://aslp-lab.github.io/HumDial-Challenge/track1/</link>
    <description>Recent content in Track1s on ICASSP 2026: Human-like Spoken Dialogue Systems Challenge</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://aslp-lab.github.io/HumDial-Challenge/track1/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/track1/results/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/track1/results/</guid>
      <description>Emotional Intelligence Track Results 1. Task Dimensions &amp;amp; Evaluation Methodology The final score for this challenge track combines both automated metrics and human evaluation to ensure the results are professional and objective.
Evaluation Environment: The automated evaluation utilizes the Qwen/Qwen3-Omni-30B-A3B-Instruct model, which is deployed entirely in a local environment for scoring. For the detailed evaluation prompts, please refer to the challenge guidelines.
Task 1: Emotional Trajectory Detection
Dimension 1: Accuracy_Completeness Dimension 2: Depth_Granularity Dimension 3: Added_Value Task 2: Emotional Reasoning</description>
    </item>
    
    <item>
      <title>Test Set</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/track1/test_set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/track1/test_set/</guid>
      <description>Test Set Description The test set (HD-Track1-Test) is now officially available, containing both Chinese (zh) and English (en) subsets. Each language subset provides 150 multi-turn dialogues for each of the three tasks (Task 1, 2 &amp;amp; 3). For each task, we provide a corresponding audio folder and a JSONL file. This file outlines the dialogue structure, such as turn order and audio file mapping.
HD-Track1-Test |_zh |__HD-Track1-T1/ |_{dialogue_id}_{turn_id}.wav |__HD-Track1-T2/ |__HD-Track1-T3/ |__HD-Track1-T1.</description>
    </item>
    
    <item>
      <title>Track 1: Emotional Intelligence</title>
      <link>https://aslp-lab.github.io/HumDial-Challenge/track1/description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aslp-lab.github.io/HumDial-Challenge/track1/description/</guid>
      <description>Challenge Tasks Task 1: Emotional Trajectory Detection - Evaluate the model&amp;rsquo;s ability to accurately identify and concisely summarize a user&amp;rsquo;s emotional changes throughout a multi-turn conversation. Task 2: Emotional Reasoning - Evaluate the model&amp;rsquo;s ability to perceive the underlying causes of a user&amp;rsquo;s emotions. Task 3: Empathy Assessment - Evaluate the model&amp;rsquo;s ability to generate empathetic responses in both text and audio formats. The final ranking will be determined based on the comprehensive score of the above three core tasks, and the specific weights of each task will be announced in subsequent stages.</description>
    </item>
    
  </channel>
</rss>
