<!DOCTYPE HTML>
<html lang="en">
    <head>

<title>Track 1: Emotion Intelligence | ICASSP 2026: Human-like Spoken Dialogue Systems Challenge</title>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
<link rel="stylesheet" href="/HumDial-Challenge/style.css" />
<meta property="og:title" content="Track 1: Emotion Intelligence" />
<meta property="og:description" content="The Emotion Intelligence Track aims to evaluate the emotional competence of spoken dialogue systems across five critical dimensions. These dimensions capture how well a system can perceive, interpret, express, and respond to human emotions in interactive scenarios" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://aslp-lab.github.io/HumDial-Challenge/task1/description/" /><meta property="article:section" content="task1" />



</head>
    <body class="is-preload">
        <div id="page-wrapper"><div id="header">
    <h1><a href="https://aslp-lab.github.io/HumDial-Challenge/" id="logo">
        Human-like-Spoken-Dialogue-Systems-Challenge - ICASSP 2026
    </a></h1>

    <nav id="nav">
        <ul>
                <li class="">
                    <a href="/HumDial-Challenge/">Home</a>
                <li class="">
                    <a href="/HumDial-Challenge/dataset/">Dataset</a>
                <li class="">
                    <a href="#">Track 1: Emotion Intelligence</a><ul>
                        <li class="">
                            <a href="/HumDial-Challenge/task1/description">description</a>
                        <li class="">
                            <a href="/HumDial-Challenge/task1/test_set">test_set</a>
                        <li class="">
                            <a href="/HumDial-Challenge/task1/leaderboard">leaderboard</a>
                    </ul>
                <li class="">
                    <a href="#">Track 2: Full-Duplex Interaction</a><ul>
                        <li class="">
                            <a href="/HumDial-Challenge/task2/description">description</a>
                        <li class="">
                            <a href="/HumDial-Challenge/task2/test_set">test_set</a>
                        <li class="">
                            <a href="/HumDial-Challenge/task2/leaderboard">leaderboard</a>
                    </ul>
                <li class="">
                    <a href="/HumDial-Challenge/faq/">FAQ</a>
        </ul>
    </nav>
</div>

            <section class="wrapper style1">
                <div class="container">
                    

                        <div class="">
                            <div id="content">
                                <article>
    <header>
        <h2>Track 1: Emotion Intelligence</h2>
        <p>The Emotion Intelligence Track aims to evaluate the emotional competence of spoken dialogue systems across five critical dimensions. These dimensions capture how well a system can perceive, interpret, express, and respond to human emotions in interactive scenarios</p>
        
        
        <ul class="tags">
</ul>

    </header><h3 id="challenge-tasks">Challenge Tasks</h3>
<ul>
<li><strong>Task 1</strong>: Emotional Trajectory Detection Task - Accurately identify and concisely summarize users&rsquo; emotional changes throughout multi-turn conversations.</li>
<li><strong>Task 2</strong>: Emotional Reasoning Task - Evaluate whether models can synthesize all conversation information to provide profound explanations.</li>
<li><strong>Task 3</strong>: Empathy Assessment Task - Assess textual and audio empathy as well as naturalness.</li>
</ul>
<p>The final ranking will be determined based on the total score of all three tasks. The specific weight allocation will be announced in subsequent stages.</p>
<p>The final ranking will be determined based on the comprehensive score of the above three core tasks, and the specific weights of each task will be announced in subsequent stages.</p>
<p>To comprehensively evaluate model performance in specific dimensions, the following supplementary tests will also be conducted:</p>
<ul>
<li><strong>Task 4</strong>: Emotional Recognition Capability Test - Identify users&rsquo; surface and deep emotional expressions.</li>
<li><strong>Task 5</strong>: Explicit Emotional Instruction Generation Capability Test - Generate natural speech expressions according to specified emotions.</li>
</ul>
<blockquote>
<p><strong>Note</strong>: The evaluation results of supplementary tasks are only used for academic analysis and reference, and will not be counted toward the final ranking score.</p>
</blockquote>
<h3 id="evaluation-framework">Evaluation Framework</h3>
<p>All submitted models will undergo automated evaluation on the test set, using a combination of large language models as judges (LLM-as-a-Judge) and human scoring.</p>
<ul>
<li><strong>Scoring Judge Model</strong>: Qwen3-Omni-30B-A3B-Instruct will be used as the automatic scoring model for the emotional trajectory detection and emotional reasoning tasks. The empathy assessment task will combine scores from Qwen3-Omni-30B-A3B-Instruct and/or other models, along with human scoring to derive the final results.</li>
<li><strong>Scoping Prompt</strong>: For detailed scoring prompt design specifications and implementation details, please refer to our provided Git repository.</li>
</ul>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h3 id="evaluation-metrics">Evaluation Metrics</h3>
<h4 id="task-1-emotional-trajectory-summary">Task 1: Emotional Trajectory Summary</h4>
<ul>
<li><strong>Accuracy_Completeness</strong>: Evaluate whether the model strictly and precisely matches and describes all emotion tags present in the conversation history, and accurately reconstructs the full emotional trajectory.<br>
<em>Score: 1, 3, or 5</em></li>
<li><strong>Depth_Granularity</strong>: Based strictly on the conversation history, does the model go beyond labeling emotions to describe the intensity and dynamics of emotional shifts in an efficient manner?<br>
<em>Score: 1, 3, or 5</em></li>
<li><strong>Added_Value</strong>: Does the summary skillfully link abstract emotion tags to concrete events in the conversation, making it feel highly personalized and easily digestible?<br>
<em>Score: 1, 3, or 5</em></li>
</ul>
<h4 id="task-2-emotional-reasoning-task">Task 2: Emotional Reasoning Task</h4>
<ul>
<li><strong>Information_Integration</strong>: Does the response utilize information from multiple turns, not just the last one? Does it demonstrate an understanding of the evolution of the topic?<br>
<em>Score: 1, 3, or 5</em></li>
<li><strong>Insight_RootCause</strong>: Does the response go beyond surface-level facts to distill deeper, unspoken psychological reasons (e.g., underlying motivations, cognitive conflicts, hidden emotional needs)?<br>
<em>Score: 1, 3, or 5</em></li>
<li><strong>Clarity_Logic</strong>: Is the explanation clear, logical, easy to understand, and does it provide a complete and justified chain of reasoning?<br>
<em>Score: 1, 3, or 5</em></li>
</ul>
<h4 id="task-3-empathy-assessment-task">Task 3: Empathy Assessment Task</h4>
<ul>
<li><strong>textual_empathy_insight</strong>: Does the text demonstrate a deep, synthesized understanding of the entire conversation, or is it a shallow summary?<br>
<em>Score: 1, 2, 3, 4 or 5</em></li>
<li><strong>vocal_empathy_congruence</strong>: Does the audio&rsquo;s emotion perfectly match the text&rsquo;s empathetic intent? This is about emotional delivery, not technical quality.<br>
<em>Score: 1, 2, 3, 4 or 5</em></li>
<li><strong>audio_quality_naturalness</strong>: How technically sound and human-like is the audio? This is about clarity, fluency, and realism.<br>
<em>Score: 1, 2, 3, 4 or 5</em></li>
</ul>


                                </article>
                            </div>
                        </div>

                    
                </div>
            </section><div id="footer">
    <div class="container">
        <div class="row">
        </div>
    </div>

    <ul class="icons">
    </ul>

    <div class="copyright">
        <ul class="menu">
            
                <li>Design: <a href="https://html5up.net">HTML5 UP</a>
                <li><a href="https://github.com/half-duplex/hugo-arcana">Theme</a>
        </ul>
    </div>
</div>
</div><script src="/HumDial-Challenge/js/jquery.min.js"></script>
<script src="/HumDial-Challenge/js/jquery.dropotron.min.js"></script>
<script src="/HumDial-Challenge/js/browser.min.js"></script>
<script src="/HumDial-Challenge/js/breakpoints.min.js"></script>
<script src="/HumDial-Challenge/js/util.js"></script>
<script src="/HumDial-Challenge/js/main.js"></script>
</body>
</html>
